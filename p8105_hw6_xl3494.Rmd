---
title: "p8105_hw6_xl3494"
author: Selina Lyu
output: github_document
---
```{r, include = FALSE}
library(tidyverse)
library(broom)
library(patchwork)
library(modelr)

set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

**Import the raw data**

```{r}
hom_raw = readr::read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

**Clean the dataset**

```{r}
hom = 
  hom_raw |>
  mutate(city_state = str_c(city,", ", state),
         solved = disposition == "Closed by arrest",
         victim_age = as.numeric(victim_age)) |>
  mutate(solved = as.integer(solved)) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ",
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

**For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors.**

```{r}
fit_balt =
  hom |>
  filter(city_state == "Baltimore, MD") |>
  mutate(
    victim_sex  = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")) |>
  glm(solved ~ victim_age + victim_sex + victim_race, data = _, family = binomial)


fit_balt_tidy =
  fit_balt |>
  broom::tidy(conf.int = TRUE) |>
  mutate(OR = exp(estimate), 
         lower_ci = exp(conf.low),
         upper_ci = exp(conf.high)) |>
  select(term, log_OR = estimate, OR, lower_ci, upper_ci, p.value) |> 
  knitr::kable(digits = 3)

fit_balt_tidy
```

Male victims’ homicide cases are about 57% less likely to be solved than female victims (OR = 0.426), holding age and race constant. We are 95% confident that the true odds ratio lies between 0.324 and 0.558.

**Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims.**

```{r, warning=FALSE}
city_or =
  hom |>
  mutate(
    victim_sex  = fct_relevel(victim_sex,  "Female"),
    victim_race = fct_relevel(victim_race, "White")
  ) |>
  group_by(city_state) |>
  nest() |>
  mutate(
    models  = map(data, \(df) glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = df, family = binomial)),
    results = map(models, \(m) tidy(m, conf.int = TRUE))
  ) |>
  unnest(results) |>
  filter(term == "victim_sexMale") |>
  mutate(
    OR    = exp(estimate),
    lower = exp(conf.low),
    upper = exp(conf.high)
  ) |>
  select (city_state, term, OR, lower, upper, p.value)

city_or
```

**Create a plot that shows the estimated ORs and CIs for each city.**

```{r, fig.height=7, fig.width=7, fig.asp=NA, out.width="80%"}
city_or |>
  ungroup() |>
  arrange(OR) |> 
  mutate(city_state = fct_reorder(city_state, OR)) |>
  ggplot(aes(x = city_state, y = OR, ymin = lower, ymax = upper)) +
  geom_pointrange() +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted OR (Male vs Female)",
    title = "Adjusted odds of homicide being solved for male vs female victims"
  )
```

According to the plot, the odds ratios in most cities are below 1, indicating that cases involving male victims are less likely to be solved than those involving female victims after adjusting for age and race. Cites like Omaha, NE, Baton Rouge, LA, and New York, NY show significant sex differences with confidence intervals excluding 1. However, cities like Albuquerque, NM, Stockton, CA, and Fresno, CA have odds ratios higher than 1, but sex difference is not significant with confidence intervals including 1. 

## Problem 2

**Load and prep the Central Park weather data**

```{r}
library(p8105.datasets)
data("weather_df")

weather = weather_df |>
  filter(name == "CentralPark_NY") |>
  select(name, tmax, tmin, prcp) |>
  drop_na()
```

**Bootstrap and fit linear regression**

```{r}
boot_res =
  tibble(strap_number = 1:5000) |>
  mutate(
    boot_samp = map(strap_number, \(i) sample_frac(weather, size = 1, replace = TRUE)),
    fit = map(boot_samp, \(df) lm(tmax ~ tmin + prcp, data = df)),
    r2 = map_dbl(fit, \(m) glance(m)$r.squared),
    results = map(fit, broom::tidy)) |>
  select(-boot_samp, -fit) |>
  unnest(results) |>
  group_by(strap_number) |>
  summarize(
    r2 = unique(r2),
    b1 = estimate[term == "tmin"],
    b2 = estimate[term == "prcp"],
    ratio = b1 / b2)

boot_res
```

**Plots**

Plot the distribution of r2

```{r}
p1 = 
  boot_res |>
  ggplot(aes(x = r2)) +
  geom_histogram() +
  labs(title = "Bootstrap Distribution of R²",
       x = "R²", y = "Count")
```

Plot the distribution of b1/b2

```{r}
p2 = 
  boot_res |>
  ggplot(aes(x = ratio)) +
  geom_histogram() +
  coord_cartesian(ylim = c(0, 500)) +
  labs(title = "Bootstrap Distribution of β1 / β2",
       x = "β1 / β2", y = "Count")
```

```{r, fig.width=8}
p1 + p2
```

**95% CI's:**

```{r}
boot_res |>
  summarize(
    r2_low  = quantile(r2, 0.025),
    r2_high = quantile(r2, 0.975),
    ratio_low  = quantile(ratio, 0.025),
    ratio_high = quantile(ratio, 0.975)) |>
  knitr::kable(digits = 3)
```

The left plot displays the bootstrap distribution of R² from repeatedly refitting the linear regression model. The distribution is symmetric and unimodal and centered around 0.91, indicating that the model consistently explains about 91% of the variation in daily maximum temperature across bootstrap samples. The spread is narrow (95% CI: 0.894, 0.928), suggesting that the R² estimate is stable and not sensitive to resampling.

In contrast, the second plot shows the bootstrap distribution of β1 / β2, the ratio of the estimated coefficients for tmin and prcp. The distribution is extremely skewed and dominated by a tall spike near zero, with a few very large positive and negative values extending far out on the x-axis. This pattern occurs because the precipitation coefficient (β2) is very close to zero, so small random variation in its estimate causes the ratio β1 / β2 to become very large in magnitude.

## Problem 3

**Load and clean dataset**

```{r}
birthweight = 
  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace   = factor(frace, levels = c(1,2,3,4,8,9), 
                     labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace   = factor(mrace, levels = c(1,2,3,4,8), 
                     labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("No", "Yes")),
    parity  = as.integer(parity),
    pnumlbw = as.integer(pnumlbw),
    pnumsga  = as.integer(pnumsga)
  ) |> 
  drop_na()
```

**Propose a regression model for birthweight -- Model 1**

```{r}
mod1 = lm(bwt ~ mheight + ppbmi + gaweeks + wtgain + smoken, data = birthweight)
```

Mother's height, pre-pregnancy BMI, gestational age, mother’s weight gain, and smoking status during pregnancy are known factors in fetal development. Therefore, I propose a regression model with those variables as predictors.

**A plot of model residuals against fitted values**

```{r}
birthweight |>
  add_predictions(mod1) |>
  add_residuals(mod1) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values (Model 1)",
    x = "Fitted birthweight",
    y = "Residuals"
  )
```

**Model 2 and 3**

```{r}
mod2 = lm(bwt ~ blength + gaweeks, data = birthweight)
mod3 = lm(bwt ~ bhead * blength * babysex, data = birthweight)
```

**Compare models using cross-validated prediction error**

```{r}
cv_df =
  crossv_mc(birthweight, 100) |>
  mutate(
    mod1 = map(train, \(df) lm(bwt ~ mheight + ppbmi + gaweeks + wtgain + smoken, data = df)),
    mod2 = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    mod3 = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df))) |>
  mutate(
    rmse_mod1 = map2_dbl(mod1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_mod2 = map2_dbl(mod2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_mod3 = map2_dbl(mod3, test, \(mod, df) rmse(model = mod, data = df)))
```

Plot the prediction error distribution for each candidate model

```{r}
cv_df |>
  select(starts_with("rmse_")) |>
  pivot_longer(
    everything(),
    names_to   = "model",
    values_to  = "rmse",
    names_prefix = "rmse_"
  ) |>
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() +
  labs(
    title = "Cross-validated RMSE by model",
    x = "Model",
    y = "RMSE")
```

From the plot, model 3 (includes head circumference, length, sex, and all interactions) has the lowest RMSE distribution, centered around 280 g, indicating it provides the most accurate predictions of birthweight among the three models. Model 1 performs the worst, while Model 2 provides moderate predictive accuracy.











